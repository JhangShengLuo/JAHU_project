{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import package\n",
    "\n",
    "# -----------manipulate data package-----------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# -----------connect to mysql package-----------\n",
    "# import pymysql\n",
    "# import sqlalchemy\n",
    "# from sqlalchemy import create_engine\n",
    "\n",
    "# -----------machine learning package-----------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve\n",
    "from xgboost import XGBClassifier,DMatrix\n",
    "from sklearn.externals import joblib # save model\n",
    "# -----------ploting package-----------\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline # plot in jupyter\n",
    "# set random seed to replicated results\n",
    "import random\n",
    "random.seed(9001) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # connect database setting\n",
    "\n",
    "# #寫入資料庫\n",
    "# user = 'user'\n",
    "# pwd = 'password'\n",
    "# port = 3306\n",
    "\n",
    "# engine_set_up = 'mysql+pymysql://{}:{}@127.0.0.1:{}/dbname?charset=utf8'\n",
    "# in_conn = create_engine(engine_set_up.format(user,pwd,port))\n",
    "# read_db_data = pd.read_sql('select * from table',con=in_conn)\n",
    "# read_db_data.to_sql('table',in_conn,if_exists='',index=False) #寫入資料庫\n",
    "\n",
    "# read_csv or excel\n",
    "# csv_data = pd.read_csv('.csv')\n",
    "# xlsx_data = pd.read_excel('.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ------delect columns------\n",
    "# del data['col']\n",
    "\n",
    "## ------rearrange columns-------\n",
    "## End to front\n",
    "# cols = df.columns.tolist()\n",
    "# cols = cols[-1:] + cols[:-1]\n",
    "# dfc = df[cols].copy() # make a copy of rearranged df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ------plotting-------\n",
    "\n",
    "# plt.figure(figsize=(10,7)) # make plot larger\n",
    "# plt.plot(x=,y=,color='blue',marker = 'o',markersize=5,label='training accuracy')\n",
    "# plt.grid() # make a grid\n",
    "# plt.xlabel('Number of training samples')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.show() # with or w/o %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ------Normalization-------\n",
    "# std_scler = StandardScaler()\n",
    "# used_col = ['col1','col2','col3']\n",
    "# X_std = std_scler.fit_transform(data[used_col])\n",
    "# test_std = std_scler.transform(test_data[used_col])\n",
    "# joblib.dump(std_scler,'std_scale.pkl') # dump normalized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ------train test split-------\n",
    "\n",
    "# X = data.iloc[:-1,:]\n",
    "# Y = data.iloc[-1:,:]\n",
    "\n",
    "# xx,tx,yy,ty = train_test_split(X[used_col],Y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## ------classification-------\n",
    "## random forest\n",
    "# rf = RandomForestClassifier(random_state=6,class_weight={0: 0.07, 1: 0.93}) # random forest with imbalanced data\n",
    "# rf.fit(xx,yy)\n",
    "\n",
    "# print('train_score',round(rf.score(xx,yy),4))\n",
    "# print('test_score',round(rf.score(tx,ty),4))\n",
    "\n",
    "# np.unique(rf.predict(xx)) # check how many label to be predicted\n",
    "\n",
    "# auc = roc_auc_score(yy, rf.predict(xx))\n",
    "# print(auc) #  check area under roc curve, as close to score is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extreme gradient boosting\n",
    "\n",
    "# xgb = XGBClassifier(random_state=6,learning_rate=0.017) # feeling better lr start with 0.017\n",
    "\n",
    "# xgb.fit(X_train_std,y)\n",
    "\n",
    "# print('train_score',round(xgb.score(X_train_std,y),4))\n",
    "# print('test_score',round(xgb.score(X_test_std,ty),4))\n",
    "# train_y_pred = xgb.predict(X_train_std)\n",
    "# print(np.unique(train_y_pred))# check how many label to be predicted\n",
    "# auc = roc_auc_score(y, train_y_pred)\n",
    "# print(auc) #  check area under roc curve, as close to score is good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # -------use SBS algorithm to find the best feature combination -------\n",
    "# from SBS import * # writting by myself but copy by book:python ml \n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=2)\n",
    "# sbs = SBS(rf,k_features=1)\n",
    "# sbs.fit(X_train_std,y)\n",
    "\n",
    "# k_feat = [len(k) for k in sbs.subsets_]\n",
    "# plt.grid(b=True)\n",
    "# plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "\n",
    "\n",
    "# peak_on_the_plot = 22\n",
    "# feature_list = list(sbs.subsets_[peak_on_the_plot])\n",
    "# print(len(feature_list)) \n",
    "\n",
    "# data.iloc[:,:-1].columns[feature_list] # assume last column is label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # -------saved needed columns in txt for future model use-------\n",
    "# need_col = data.iloc[:,:-1].columns[feature_list] # assume last column is label\n",
    "# np.savetxt('need_col.txt', need_col.values,fmt='%s,', delimiter=',') \n",
    "# # sort_importance feature\n",
    "# feature_import_sort = data.iloc[:,:-1].columns[feature_list][rf.feature_importances_.argsort()[::-1]]\n",
    "# np.savetxt('need_col_feature_import_sort.txt', feature_import_sort.values,fmt='%s,', delimiter=',') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
